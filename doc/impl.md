## Files(leveldb 中的各种文件)

每个 leveldb 的实现类似于一个单独的 [Bigtable tablet (section 5.3)](http://research.google.com/archive/bigtable.html), 但是它的文件组织有点不同. 

每个 leveldb database 就是存储到某个目录下的一组文件. 这些文件分为如下几种: 

### Log files (日志文件)

一个 log 文件(*.log)保存着最近一系列更新操作, 它相当于 leveldb 的 WAL(write-ahead log). 每个更新操作都被追加到当前的 log 文件中. 当 log 文件大小达到一个预定义的大小时(默认大约 4MB), 这个 log 文件就会被转换为一个 sorted string table (见下文)然后一个新的 log 文件就会被创建以保存未来的更新操作. 

当前 log 文件内容同时也会被记录到一个内存数据结构中(即 `memtable`). 这个结构加上全部 sorted string tables (*.ldb) 才是完整数据, 一起确保每个读操作都能查到当前最新. 

## sorted string tables

sorted string table(*.ldb) 文件就是 leveldb 的数据库文件了. 每个 sorted string table 文件保存着按 key 排序的一系列数据项. 每个数据项要么是一个与某个 key 对应的 value, 要么是某个 key 的删除标记. (删除标记其它地方又叫墓碑消息, 用于声明时间线上在此之前的同名 key 对应的记录都失效了, 后台线程负责对这类记录进行压实, 即拷贝到另一个文件时物理删除这类记录.). 注意, leveldb 是一个 append 类型而非 MySQL 那种 in-place 修改的数据库.

sorted string tables 文件被组织成一系列 levels. 一个 log 文件生成的对应 sorted string table 文件会被放到一个特殊的 **young** level(也被叫做 level-0). 当 young 文件数目超过某个阈值(当前是 4), 全部 young 文件就会和 level-1 与之重叠的全部文件进行合并, 进而生成一系列新的 level-1 文件(每 2MB 数据就会生成一个新的 level-1 文件). 

young level 的文件之间可能存在键区间重叠, 但是其它每层 level 内部文件之间是不存在重叠情况的. 我们下面来说下 level-1 及其以上的 level 的文件如何合并. 当 level-L (L >= 1)的文件总大小超过了 10^L MB(即 level-1 超过了 10MB, level-2 超过了 100MB, ...), 此时一个 level-L 文件就会和 level-(L+1) 中与自己键区间重叠的全部文件进行合并, 然后为 level-(L+1) 生成一组新的文件. 这些合并操作可以实现将 young level 中新的 updates 一点一点搬到最高的那层 level, 这个迁移过程使用的都是块读写(最小化了昂贵的 seek 操作的时间消耗). 

### Manifest

MANIFEST 文件可以看作 leveldb 存储元数据的地方. 它列出了每一个 level 及其包含的全部 sorted string table 文件, 每个 sorted string table 文件对应的键区间, 以及其它重要的元数据. 每当重新打开数据库的时候, 就会创建一个新的 MANIFEST 文件(文件名中嵌有一个新生成的数字). MANIFEST 文件被格式化成日志文件, 针对它所服务的数据的变更都会被追加到该文件后面. 比如每当某个 level 发生文件新增或者删除操作时, 就会有一条日志被追加到 MANIFEST 中. 

### Current

CURRENT 文件是一个简单的文本文件. 由于每次重新打开数据库都会生成一个 MANIFEST 文件, 所以需要一个地方记录最新的 MANIFEST 文件是哪个, CURRENT 就干这个事情, 它相当于一个指针, 其内容即是当前最新的 MANIFEST 文件的名称. 

### Info logs

LOG 或者 LOG.old 文件是保存 leveldb 运行日志的地方.

### Others

其它文件被用于比较零碎的目的, 现有的其它文件有 LOCK、*.dbtmp. 

## Level 0

当一个 log 文件大小超过某个值(默认 4MB): 

就会创建一个全新的 memtable 和 log 文件, 新的 updates 就会写到这里. 

同时在后台: 

1. 将前一个 memtable 内容写到一个 sstable 即 sorted string table 文件. 
2. 丢弃这个 memtable. 
3. 删除老的 log 文件和老的 memtable. 
4. 把新生成的 sstable 放到到 level-0. 

## Compactions 压实

当 level-L 大小超过了上限, 具体来说就是 level-0 文件数超过 4 个, level-L(L>=1) 文件总大小好过 $10^L$MB, 就会触后台线程的压实操作. 压实过程会从 level-L(L>=1) 挑一个文件, 然后将 level-(L+1) 中与该文件键区间重叠的文件都找出来. 注意, 即使一个 level-L 文件仅仅与 level-(L+1) 重叠了一部分, 那么 level-(L+1) 的这个文件也会整个作为压实过程的输入, 等压实结束后该文件就会被丢弃. 另外, 因为 level-0 比较特殊(该层的文件之间可能相互重叠), 我们会把 level-0 到 level-1 的压实过程做特殊处理: 我们每次会从 level-0 选取相互重叠的全部文件, 而不是像其它 level 一样只选取一个文件, 然后将其合并为一个文件然后再和 level-1 与其重叠的文件进行合并. 

一次压实会合并多个文件的内容从而生成一系列新的 level-(L+1) 文件, 生成一个新文件的条件有两个: 当前文件达到了 2MB 大小或者当前文件的键区间与超过 10 个 level-(L+2) 文件发生了重叠(还记得前面的 MANIFEST 文件吗? 它记录了每一个 level 的文件及其键区间). 第二个条件的目的在于避免后续对 level-(L+1) 文件进行压实时需要从 level-(L+2) 读取过多的数据. 

压实后, 旧的文件会被丢弃, 新生成的文件开始生效并将其变更日志追加到 MANIFEST 中. 

针对某一个 level 的压实会循环该 level 覆盖的整个键空间. 具体来讲, 针对 level L, 我们会记住 level L 上次压实的最后一个 key. 针对 level L 的下次压实将会挑选从这个 key 之后开始的第一个文件进行. (如果不存在这样的文件, 那么就会遍历回键空间起始 key). 

压实会丢弃某个 key 对应的被覆盖过的 values(只保留时间线上最新的那个 value), 也会在没有更高的 level 包含该 key 的时候丢弃针对这个 key 的删除标记(level 越高数据越老, 所以如果某个 key 被在下层标记为删除, 在合并全部上层针对该 key 的操作之前该标记不能移除否则会被查询过程感知到老数据). 

### Timing 压实时间消耗

Level-0 压实将会从 level-0 读取 4 个 1MB 文件(log 文件说明部分提到当 log 文件增长到 4MB 就会被转成一个 sorted string table, 这里看应该是转成 4 个, 每个 1MB 大小. compaction 部分提到 level-0 文件个数达到 4 就触发 level-0 压实, 这么看应该是每次 log 达到 4MB 会触发 sorted string table 生成, 同时会触发压实.), 最坏情况下同时会把 level-1 全部 10MB 文件都读进来(即该层全部文件都和 level-0 有重叠). 这种情况下我们会读取 14MB 写入 14MB. 

除了特殊的 level-0 压实过程, 我们会从 level L 选取一个 2MB 大小的文件. 最坏情况下, 这会与 level L+1 层大约 12 个文件发生重叠(其中 10 个是因为 level-(L+1) 大小是 level-L 的十倍所以是 10 个, 另外 2 个(作为前面提到的 10 个文件前后的边界文件)是因为 level-L 的文件区间通常不与 level-(L+1) 对齐). 因此压实会读取 26MB 写入 26MB. 假设磁盘 IO 速度为 100MB/s(现代的磁盘驱动大约就这速度), 最坏情况下的压实将会消耗大约 0.5 秒(读写共 52MB, 读或者写都需要寻道, 两个操作是串行的). 

假如我们把后台写入速度限制到一个比较小的值, 比如全速(100MB/s) 的 10%, 上面提到的一次压实大约消耗 5 秒. 如果用户以 10MB/s 的速度写磁盘, 我们可能会生成大量的 level-0 文件(写得慢, 合并就慢, 就会导致 level-0 文件变多)(5 秒, 每秒 10MB, 每个 level-0 文件 1MB, 那么就是大约 50 个文件来保存 5*10MB 数据). 这会显著增加读操作时间消耗, 因为压实进行的慢, 导致每次查询操作需要读取更多文件(因为 level-0 文件键区间可能彼此重叠, 压实进行得慢就会有非常多小文件, 为了获取需要的数据, 每次读都需要合并这些文件进行去重).

解决方案 1: 为了缓解这个问题的影响, 我们可能会想要在 level-0 文件太多的时候调大 log 文件转换为 sorted string table 的阈值. 但这么做的缺点是, 这个阈值越大, 我们需要更多的内存来维持其对应的 memtable. 

解决方案 2: 我们可能想要在 level-0 文件个数蹿升时人工减小写入速度(这里的写入指的是外部调用 leveldb 写操作的速度, 而不是磁盘写入速度). 

解决方案 3: 我们设法减少大范围合并操作的消耗. 或许大多数 level-0 文件对应的块未被压缩而且仍然处于 cache 中, 我们不需要去读磁盘, 这时我们只需操心合并时的 O(N) 复杂度. 

### Number of files 文件个数的影响

不再总是构造大小为 2MB 大小的文件, 我们可以为更高的 level 构造更大的文件以减少总的文件个数, 虽然这样会导致更加猝发式(发生时机突然, 而且量非常大)地压实操作. 或者, 我们可以将同一组文件分片到多个目录中. 

2011 年 2 月 4 号, 我们在一个 ext3 文件系统上做了针对包含不同文件个数的目录打开十万次文件的时间消耗测试: 

|目录中的文件数         | 打开一个文件的微秒数          |
|-------------------:|----------------------------:|
|               1000 |                           9 |
|              10000 |                          10 |
|             100000 |                          16 |

测试结果显示差别不太大, 在现代文件系统上, 将文件分片到更多目录可能不是必须的. 

## Recovery 打开数据库时的恢复过程

- 读取 CURRENT 文件找到最新的 MANIFEST 文件的名称
- 读取该 MANIFEST 文件内容
- 清理过期的文件
- 这一步我们可以打开全部 sstables, 但最好等会再打开
- 如果当前 log 文件未到大小上限则继续使用, 否则转换为一个新的 level-0 sstable 写入磁盘再重新创建一个 log 文件
- 将接下来的要写的数据写入 log 文件

## Garbage collection of files

每次压实结束或者恢复结束 `DeleteObsoleteFiles()` 方法就会被调用. 该方法会找到数据库中的全部文件的名称. 它会删除全部的非当前 log 文件, 也会删除全部无效的 table 文件(这些 table 文件不再被任何 level 引用且不是某个正在进行的压实过程的输出文件). 
